{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9960547-640d-425c-8180-fc5523a80e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import geoarrow.pyarrow as ga\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pystac_client\n",
    "import requests\n",
    "import torch\n",
    "import yaml\n",
    "from box import Box\n",
    "from stacchip.chipper import Chipper\n",
    "from stacchip.indexer import Sentinel2Indexer\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fec81-2cc1-4c5a-9e46-7c46a5591484",
   "metadata": {},
   "source": [
    "### Find data for AOI\n",
    "The first step is to find STAC items of imagery that we want to use to create embeddings. In this example we are going to use Earth Genome's composite dataset which comes with a great STAC catalog.\n",
    "\n",
    "We are also going to create embeddings along time so that we have multiple embeddings for the same location at different moments in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1d46ee-40f6-49f5-99ad-83819339561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point over Monchique Portugal\n",
    "lat, lon = 37.30939, -8.57207\n",
    "\n",
    "# Dates of a large forest fire\n",
    "start = \"2018-07-01\"\n",
    "end = \"2018-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7825318-23f3-449f-9104-eae6562a55ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 items\n"
     ]
    }
   ],
   "source": [
    "# Optimize GDAL settings for cloud optimized reading\n",
    "os.environ[\"GDAL_DISABLE_READDIR_ON_OPEN\"] = \"EMPTY_DIR\"\n",
    "os.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\n",
    "\n",
    "STAC_API = \"https://earth-search.aws.element84.com/v1\"\n",
    "COLLECTION = \"sentinel-2-l2a\"\n",
    "\n",
    "# Search the catalogue\n",
    "catalog = pystac_client.Client.open(STAC_API)\n",
    "search = catalog.search(\n",
    "    collections=[COLLECTION],\n",
    "    datetime=f\"{start}/{end}\",\n",
    "    bbox=(lon - 1e-5, lat - 1e-5, lon + 1e-5, lat + 1e-5),\n",
    "    max_items=100,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 80}},\n",
    ")\n",
    "\n",
    "all_items = search.get_all_items()\n",
    "\n",
    "# Reduce to one per date (there might be some duplicates\n",
    "# based on the location)\n",
    "items = []\n",
    "dates = []\n",
    "for item in all_items:\n",
    "    if item.datetime.date() not in dates:\n",
    "        items.append(item)\n",
    "        dates.append(item.datetime.date())\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f3cfb-ce4e-4409-ae15-20f3a7107a62",
   "metadata": {},
   "source": [
    "To speed up processing in this example, we limit the number of chips to 3 per Sentinel-2 scene. Remove this limit in a real use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183975c7-8afb-49ef-8e70-790265719aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on <Item id=S2A_29SNB_20180828_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180823_1_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180818_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180813_0_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180808_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180803_1_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180729_1_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180724_0_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180719_0_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180714_0_L2A>\n",
      "Working on <Item id=S2A_29SNB_20180709_0_L2A>\n",
      "Working on <Item id=S2B_29SNB_20180704_0_L2A>\n"
     ]
    }
   ],
   "source": [
    "chips = []\n",
    "datetimes = []\n",
    "bboxs = []\n",
    "chip_ids = []\n",
    "item_ids = []\n",
    "\n",
    "for item in items:\n",
    "    print(f\"Working on {item}\")\n",
    "\n",
    "    # Index the chips in the item\n",
    "    indexer = Sentinel2Indexer(item)\n",
    "\n",
    "    # Instanciate the chipper\n",
    "    chipper = Chipper(indexer, assets=[\"red\", \"green\", \"blue\", \"nir\", \"scl\"])\n",
    "\n",
    "    # Get first chip for the \"image\" asset key\n",
    "    for idx, (x, y, chip) in enumerate(chipper):\n",
    "        if idx > 2:\n",
    "            break\n",
    "        del chip[\"scl\"]\n",
    "        chips.append(chip)\n",
    "        datetimes.append(item.datetime)\n",
    "        bboxs.append(indexer.get_chip_bbox(x, y))\n",
    "        chip_ids.append((x, y))\n",
    "        item_ids.append(item.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71902ab7-3320-43cd-85c3-362c2500f241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4, 256, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels = np.array([np.array(list(chip.values())).squeeze() for chip in chips])\n",
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e886d3f-50c4-4a04-bc8a-eea5235394cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"https://raw.githubusercontent.com/Clay-foundation/model/refs/heads/main/configs/metadata.yaml\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(metadata_path, headers=headers)\n",
    "content = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f7ce367-4e12-4648-bb79-119b4f50ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean, std, and wavelengths from metadata\n",
    "platform = \"sentinel-2-l2a\"\n",
    "\n",
    "# Load the metadata\n",
    "content = yaml.safe_load(content)\n",
    "\n",
    "metadata = Box(content)\n",
    "mean = []\n",
    "std = []\n",
    "waves = []\n",
    "# Use the band names to get the correct values in the correct order.\n",
    "for band in chips[0].keys():\n",
    "    mean.append(metadata[platform].bands.mean[band])\n",
    "    std.append(metadata[platform].bands.std[band])\n",
    "    waves.append(metadata[platform].bands.wavelength[band])\n",
    "\n",
    "# Prepare the normalization transform function using the mean and std values.\n",
    "transform = v2.Compose(\n",
    "    [\n",
    "        v2.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8ec8c2d-ecb9-42a2-9e8c-3f95c67ef07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_timestamp(date):\n",
    "    week = date.isocalendar().week * 2 * np.pi / 52\n",
    "    hour = date.hour * 2 * np.pi / 24\n",
    "\n",
    "    return (math.sin(week), math.cos(week)), (math.sin(hour), math.cos(hour))\n",
    "\n",
    "\n",
    "times = [normalize_timestamp(dat) for dat in datetimes]\n",
    "week_norm = [dat[0] for dat in times]\n",
    "hour_norm = [dat[1] for dat in times]\n",
    "\n",
    "\n",
    "# Prep lat/lon embedding using the\n",
    "def normalize_latlon(lat, lon):\n",
    "    lat = lat * np.pi / 180\n",
    "    lon = lon * np.pi / 180\n",
    "\n",
    "    return (math.sin(lat), math.cos(lat)), (math.sin(lon), math.cos(lon))\n",
    "\n",
    "\n",
    "latlons = [normalize_latlon(lat, lon)] * len(times)\n",
    "lat_norm = [dat[0] for dat in latlons]\n",
    "lon_norm = [dat[1] for dat in latlons]\n",
    "\n",
    "# Prep gsd\n",
    "gsd = [10]\n",
    "\n",
    "# Normalize pixels\n",
    "pixels = transform(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2640eb17-a85c-4972-8d5d-e45e9ed8eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = {\n",
    "    \"pixels\": torch.tensor(pixels, dtype=torch.float32),\n",
    "    \"time\": torch.tensor(np.hstack((week_norm, hour_norm)), dtype=torch.float32),\n",
    "    \"latlon\": torch.tensor(np.hstack((lat_norm, lon_norm)), dtype=torch.float32),\n",
    "    \"waves\": torch.tensor(waves, dtype=torch.float32),\n",
    "    \"gsd\": torch.tensor(gsd, dtype=torch.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f6711a9-e7ed-44d5-add7-2c3a498cd422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixels torch.Size([36, 4, 256, 256])\n",
      "time torch.Size([36, 4])\n",
      "latlon torch.Size([36, 4])\n",
      "waves torch.Size([4])\n",
      "gsd torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in datacube.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83243912-a2a8-4fa5-a39c-a9c3b07c7569",
   "metadata": {},
   "source": [
    "### Clay Embedder\n",
    "\n",
    "#### Load the embedder that is stored in ExportedProgram format using **cpu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b81249-a222-4bd0-bdce-eacb704c0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://huggingface.co/made-with-clay/Clay/resolve/main/v1.5/compiled/clay-v1.5-encoder-cpu.pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9eb797f7-5238-49e0-9950-e85f10132454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 842 ms, total: 3.02 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ep_embedder_cpu = torch.export.load(\"clay-v1.5-encoder-cpu.pt2\").module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eefe4811-7290-47c3-a10e-45257e6d42e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 8s, sys: 19.3 s, total: 7min 27s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([36, 4, 256, 256]), torch.Size([36, 1024]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    embeddings = ep_embedder_cpu(datacube)\n",
    "datacube[\"pixels\"].shape, embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e927b01-c855-4172-a4d9-2c10ba794ed4",
   "metadata": {},
   "source": [
    "For each chip, we have an embedding of size `1024`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0810b4-34ad-490e-bbcd-c0c3288f017c",
   "metadata": {},
   "source": [
    "#### Load the embedder that is stored in ExportedProgram format using **gpu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af43ee69-2f5a-4b86-868d-383856f30b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://huggingface.co/made-with-clay/Clay/resolve/main/v1.5/compiled/clay-v1.5-encoder.pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05e8d7-7ebb-4c54-8096-453479c7dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = {k: v.to(\"cuda\") for k, v in datacube.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "235465bb-7080-4b3e-aadf-e5e656d5128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.33 s, sys: 1 s, total: 3.33 s\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ep_embedder = torch.export.load(\"clay-v1.5-encoder.pt2\").module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edefee90-e6b8-4701-bb5d-2bf7febc806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.1 ms, sys: 0 ns, total: 47.1 ms\n",
      "Wall time: 17 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([36, 4, 256, 256]), torch.Size([36, 1024]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    embeddings = ep_embedder(datacube)\n",
    "datacube[\"pixels\"].shape, embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f2121-46b5-4b02-94d3-75e648c329c3",
   "metadata": {},
   "source": [
    "For each chip, we have an embedding of size `1024`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1cb0f9-a434-419b-a88b-4d4edd84fea6",
   "metadata": {},
   "source": [
    "#### Load the embedder that is stored in ONNX format using **cpu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa10d696-740a-458e-ae10-eec9a43fb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3084a11e-3dbd-4eca-ac55-c7c9055dd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://huggingface.co/made-with-clay/Clay/resolve/main/v1.5/compiled/clay-v1.5-encoder-cpu.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc3fa967-73d5-431c-88a2-84b088aff06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = {k: v.to(\"cpu\") for k, v in datacube.items()}\n",
    "onnx_embedder = ort.InferenceSession(\n",
    "    \"clay-v1.5-encoder-cpu.onnx\", providers=[\"CPUExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24591d17-d1c8-452b-9b20-676a9b6f8643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 17s, sys: 3.29 s, total: 12min 20s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 1024)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = onnx_embedder.run(\n",
    "    [],\n",
    "    {\n",
    "        \"cube\": datacube[\"pixels\"].numpy(),\n",
    "        \"time\": datacube[\"time\"].numpy(),\n",
    "        \"latlon\": datacube[\"latlon\"].numpy(),\n",
    "        \"waves\": datacube[\"waves\"].numpy(),\n",
    "        \"gsd\": datacube[\"gsd\"].numpy(),\n",
    "    },\n",
    ")[0]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07216e-a109-4cd8-8c74-9a3fc9a37757",
   "metadata": {},
   "source": [
    "For each chip, we have an embedding of size `1024`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d5900-9a4b-4e2d-b992-4fb0a1e8c835",
   "metadata": {},
   "source": [
    "### Store the results\n",
    "\n",
    "We create a table containing the embeddings, bounding box, the STAC item ID, the datetime of the image capture, and the chip x and y ids. Then we save that data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "677f04d3-db38-4d44-9b55-c103d54adcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "datetimes: timestamp[us, tz=UTC]\n",
       "chip_ids: list<item: int64>\n",
       "  child 0, item: int64\n",
       "item_ids: string\n",
       "emeddings: list<item: float>\n",
       "  child 0, item: float\n",
       "geometry: extension<geoarrow.polygon<PolygonType>>\n",
       "----\n",
       "datetimes: [[2018-08-28 11:30:56.771000Z,2018-08-28 11:30:56.771000Z,2018-08-28 11:30:56.771000Z,2018-08-23 11:30:50.574000Z,2018-08-23 11:30:50.574000Z,...,2018-07-09 11:24:55.535000Z,2018-07-09 11:24:55.535000Z,2018-07-04 11:30:35.271000Z,2018-07-04 11:30:35.271000Z,2018-07-04 11:30:35.271000Z]]\n",
       "chip_ids: [[[0,0],[1,0],...,[1,0],[2,0]]]\n",
       "item_ids: [[\"S2A_29SNB_20180828_1_L2A\",\"S2A_29SNB_20180828_1_L2A\",\"S2A_29SNB_20180828_1_L2A\",\"S2B_29SNB_20180823_1_L2A\",\"S2B_29SNB_20180823_1_L2A\",...,\"S2A_29SNB_20180709_0_L2A\",\"S2A_29SNB_20180709_0_L2A\",\"S2B_29SNB_20180704_0_L2A\",\"S2B_29SNB_20180704_0_L2A\",\"S2B_29SNB_20180704_0_L2A\"]]\n",
       "emeddings: [[[0.08737555,0.09504964,0.053098626,-0.08628022,-0.048699543,...,-0.0032533202,-0.25458118,-0.022807367,-0.0469472,0.05704065],[0.08689095,0.0950256,0.05296232,-0.086429946,-0.048633248,...,-0.0032212846,-0.25452533,-0.022898452,-0.046709128,0.056958135],...,[0.03925299,0.089633435,0.09663132,-0.082739085,-0.06601126,...,0.008832958,-0.22275919,-0.02150431,-0.03782634,0.038381614],[0.037446644,0.08881048,0.10225959,-0.08421981,-0.06807363,...,0.009247402,-0.22108649,-0.021674152,-0.037864573,0.03648282]]]\n",
       "geometry: [[[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.825403979293151,-8.825730459265694,-9.000227209792856,-9.000227635454767,-8.825403979293151]\n",
       "      -- child 1 type: double\n",
       "[37.947460030545635,37.809019655564406,37.809148556380286,37.947589571562965,37.947460030545635]],[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.650582567535476,-8.651235936821893,-8.825730459265694,-8.825403979293151,-8.650582567535476]\n",
       "      -- child 1 type: double\n",
       "[37.94707073614538,37.80863228507305,37.809019655564406,37.947460030545635,37.94707073614538]],...,[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.650582567535476,-8.651235936821893,-8.825730459265694,-8.825403979293151,-8.650582567535476]\n",
       "      -- child 1 type: double\n",
       "[37.94707073614538,37.80863228507305,37.809019655564406,37.947460030545635,37.94707073614538]],[      -- is_valid: all not null\n",
       "      -- child 0 type: double\n",
       "[-8.475765647330832,-8.476745873271028,-8.651235936821893,-8.650582567535476,-8.475765647330832]\n",
       "      -- child 1 type: double\n",
       "[37.94642170369997,37.80798646012822,37.80863228507305,37.94707073614538,37.94642170369997]]]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write data to pyarrow table\n",
    "index = {\n",
    "    \"datetimes\": datetimes,\n",
    "    \"chip_ids\": chip_ids,\n",
    "    \"item_ids\": item_ids,\n",
    "    \"emeddings\": [np.ascontiguousarray(dat) for dat in embeddings],\n",
    "    \"geometry\": ga.as_geoarrow([dat.wkt for dat in bboxs]),\n",
    "}\n",
    "table = pa.table(index)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d62a9e8a-b4f9-491c-a437-6a164a9e74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table, \"embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fb8c7-d04d-453f-93f6-dc3599f1df15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
